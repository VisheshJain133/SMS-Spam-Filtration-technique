{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuyDwZMogt04",
        "outputId": "38f169fe-cbf7-4885-d562-0b61dc000e69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the path specified.\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "[WinError 1314] A required privilege is not held by the client: '/kaggle/input' -> '..\\\\input'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(KAGGLE_WORKING_PATH, \u001b[38;5;241m0o777\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m   \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKAGGLE_INPUT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m..\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_is_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "\u001b[1;31mOSError\u001b[0m: [WinError 1314] A required privilege is not held by the client: '/kaggle/input' -> '..\\\\input'"
          ]
        }
      ],
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'spam-text-message-classification:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2050%2F3494%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240409%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240409T105908Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db3348b8b3b578a712f52615e00a7de2868390ea9635290bb60089158bfa4d05c970ee5a3d4b81fbf05d9e2ada3376efcf1589438173ef63c1a35962a730f039b30c06aec5d2118beb4ced9992a9fe3c8e800e8b8e800ebf07141526070f7825841e180834ba2c03e87d68a95d8fadb8aed22f47518518b369824807716b2ce77f72f69da77657786fbd957995b50ac09174a810f6b356bce95ed6124bf3ed83248feb9b4a015129e44dbd2e608a2e8470a30443bacf0dfd234897546b434202afb59a405a8cd04324467f386a22dc6ebc293985e9f9734b1bd220b9410041dfe8d30fd8ab6c98e78052ff9f77cae67d292a3798a5b943205961e0d564713ae2b'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwdardpTzQLz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3uHvjYggt05"
      },
      "source": [
        "# **Introduction**\n",
        "---\n",
        "\n",
        "The **\"Spam Text Message Classification\"** dataset is a **collection of text messages** that have been **labeled** as either **spam or ham (not spam).** The dataset contains **5,572** messages in total, with **4,827 messages** labeled **as ham** and **747** messages **labeled as spam**.\n",
        "\n",
        "**Each message** in the **dataset** is represented as a **string** and has a **corresponding label** indicating whether it is **spam or ham**. The dataset was created by **Team AI** and was **last updated** in **October 2020**.\n",
        "\n",
        "The purpose of the **dataset** is to provide a resource for the **development** and **evaluation** of **text classification models** for **spam detection**. This is a **common task** in **natural language processing**, as **spam messages** can be a **significant problem** for **individuals and organizations alike**.\n",
        "\n",
        "**Problem at hand**\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "The **problem at hand** is **spam detection** in **text messages**. **Spam messages** are **unsolicited messages** that are sent to a **large number of people**, often with the **intention of advertising** a **product or service** or of **committing fraud**. **Spam messages** can be a **nuisance** and can **even be dangerous**, as they may **contain links** to **malicious websites or phishing scams**.\n",
        "\n",
        "The **goal of spam detection** is to develop models that can **accurately classify incoming text messages** as either **spam or legitimate (also known as \"ham\")**. This is a **challenging problem** because **spammers are constantly evolving** their **tactics to avoid detection**, and the **content of spam messages can be highly variable**.\n",
        "\n",
        "# **Notebook Structure**\n",
        "---\n",
        "\n",
        "* **SetUp** : This section involves importing all the necessary modules required for the execution of the program. We also define the hyperparameters and constants that are required for the successful implementation of the program.\n",
        "\n",
        "* **Data Loading** : In this step, we load the data into our program, which is a crucial first step towards working with and analyzing the data.\n",
        "\n",
        "* **Text Preprocessing** : Currently, the data is in RAW format, so we focus on preprocessing the text so that it can be fed to the model. This section involves text vectorization, including steps such as tokenization, cleaning, and padding.\n",
        "\n",
        "* **Transformer Network Architecture** : This section focuses on creating the required layers for the transformer network architecture, such as the token and word embeddings and the position embeddings, including the transformer layer.\n",
        "\n",
        "* **Transformer Model Training** : In this section, we train the model using the transformer network architecture created in the previous section. We also evaluate the model's performance on the testing data to understand how well the model is performing. Looking at the training curve, you might think that the model is diverging. But once we evaluate the model's performance on the testing data, we see that the model is performing great and able to generalize on new samples. This shows that the model weights are robust and will work on new samples. Although the architecture is simple, we are still achieving excellent performance.\n",
        "\n",
        "* **Transformer Model Predictions** : In this section, we create a function that allows us to input text, and the transformer will be able to recognize whether the input is spam or ham. This section focuses on using the model to make predictions on new data.\n",
        "\n",
        "By following this structure, we can build a comprehensive and organized notebook that is easy to follow and understand, making it easier to implement and modify the model as required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xTm3auZgt06"
      },
      "source": [
        "# **SetUp**\n",
        "---\n",
        "\n",
        "Here, we are **importing all the necessary modules** required for the **execution of the program**. In addition to that, we are also **defining the hyperparameters and constants** that are required for the **successful implementation of the program**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MOtsaPW6gt06"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Common imports\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Data processing and visualization imports\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Data processing and visualization imports\n",
        "import string\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import tensorflow.data as tfd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Model building imports\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras import Model, layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ_Q_KYvgt06"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters\n",
        "num_heads = 4\n",
        "embed_dim = 256\n",
        "ff_dim = 128\n",
        "vocab_size = 10000\n",
        "max_seq_len = 40\n",
        "\n",
        "# Set constants\n",
        "learning_rate = 1e-3\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "# Define training callbacks\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    keras.callbacks.ModelCheckpoint(\"SpamDetector.h5\", save_best_only=True)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtvHfoNngt06"
      },
      "outputs": [],
      "source": [
        "# Set up random seed for reproducibility\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewSgpBS4gt06"
      },
      "source": [
        "# **Data Loading**\n",
        "\n",
        "---\n",
        "In this step, we begin the **process of loading the data** into our program, which is a **crucial first step** towards being able to **work with and analyze the data**. Without **properly loading the data**, we **would not be able to perform any further data processing or analysis**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gnLNiyAWgt06",
        "outputId": "839b9610-cf5f-4e48-9a38-8b7516c15949"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data_frame\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5157,\n        \"samples\": [\n          \"Also sir, i sent you an email about how to log into the usc payment portal. I.ll send you another message that should explain how things are back home. Have a great weekend.\",\n          \"Are you free now?can i call now?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data_frame"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0bd513c3-7e67-4e01-a916-ef3019d19225\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bd513c3-7e67-4e01-a916-ef3019d19225')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0bd513c3-7e67-4e01-a916-ef3019d19225 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0bd513c3-7e67-4e01-a916-ef3019d19225');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5258f129-64a9-4aee-abed-cf5e5b3649d5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5258f129-64a9-4aee-abed-cf5e5b3649d5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5258f129-64a9-4aee-abed-cf5e5b3649d5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  Category                                            Message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Specify the path to the SPAM text message dataset\n",
        "data_path = 'C:\\Users\\VISHESH JAIN\\OneDrive\\Desktop\\sms spam\\SPAM text message 20170820 - Data.csv'\n",
        "\n",
        "# Load the dataset using the load_data function\n",
        "data_frame = pd.read_csv(data_path)\n",
        "\n",
        "# Print the first five rows of the dataset\n",
        "data_frame.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpR4tIuigt06"
      },
      "source": [
        "Let's gather some deeper data informations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "a_FB1hyggt07",
        "outputId": "e689528a-fec7-4dc4-a82a-a5d8f538da8b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"9b753f7e-d5da-45bd-8c54-1cc4b839abf3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9b753f7e-d5da-45bd-8c54-1cc4b839abf3\")) {                    Plotly.newPlot(                        \"9b753f7e-d5da-45bd-8c54-1cc4b839abf3\",                        [{\"customdata\":[[\"ham\"],[\"spam\"]],\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hole\":0.4,\"hovertemplate\":\"Class=%{label}\\u003cbr\\u003evalue=%{value}\\u003cbr\\u003ecolor=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"labels\":[\"ham\",\"spam\"],\"legendgroup\":\"\",\"marker\":{\"colors\":[\"#636efa\",\"#EF553B\"]},\"name\":\"\",\"showlegend\":true,\"values\":[4825,747],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"tracegroupgap\":0,\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"title\":{\"text\":\"Class Distribution of Spam Text Messages\"},\"margin\":{\"l\":10,\"r\":10,\"t\":60,\"b\":10}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9b753f7e-d5da-45bd-8c54-1cc4b839abf3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get the counts of each class and their names\n",
        "class_dis = data_frame.Category.value_counts()\n",
        "class_names = class_dis.index\n",
        "\n",
        "# Create the Pie Chart\n",
        "fig = px.pie(names=class_names,\n",
        "             values=class_dis,\n",
        "             color=class_names,\n",
        "             hole=0.4,\n",
        "             labels={'value': 'Count', 'names': 'Class'},\n",
        "             title='Class Distribution of Spam Text Messages')\n",
        "\n",
        "# Customize the layout\n",
        "fig.update_layout(\n",
        "    margin=dict(l=10, r=10, t=60, b=10),\n",
        "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbZwI5ZWgt07"
      },
      "source": [
        "After analyzing the **data set**, it is **evident** that the **class distribution** is **highly skewed**. Specifically, **86.6% of the data points** belong to the **\"ham\"** class, while **only 13.4% of the data points** belong to the **\"spam\" class**. This **substantial class imbalance** suggests that **even a random guesser** could **classify instances correctly approximately 86%** of the **time**, rendering any prediction model **unreliable and ineffective.** We will deal with the problem of **Class Imbalance** in next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkAnZAeMgt07",
        "outputId": "b201c667-ddf4-4c71-c82e-650bd9159c83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Samples : 5572\n"
          ]
        }
      ],
      "source": [
        "# Data set size\n",
        "N_SAMPLES = len(data_frame)\n",
        "\n",
        "print(f\"Total Number of Samples : {N_SAMPLES}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS3a3fAVgt07"
      },
      "source": [
        "The data is **neither too big, nor too small**. ALthough, it is still **quite small**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xolQsAYrgt07",
        "outputId": "1b3df4c2-1111-4b18-f618-a68780e7154f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum Length Of Input Sequence(Chars) : 910\n"
          ]
        }
      ],
      "source": [
        "max_len = max([len(text) for text in data_frame.Message])\n",
        "print(f\"Maximum Length Of Input Sequence(Chars) : {max_len}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o9SyqoZgt07",
        "outputId": "49ff01c2-63ef-4c50-bc7b-ac5f8d28be30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X[:5]: \n",
            "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'Ok lar... Joking wif u oni...', \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", 'U dun say so early hor... U c already then say...', \"Nah I don't think he goes to usf, he lives around here though\"]\n",
            "\n",
            "y[:5]: [0 0 1 0 0]\n",
            "\n",
            "Label Mapping : ['ham' 'ham' 'spam' 'ham' 'ham']\n"
          ]
        }
      ],
      "source": [
        "# Extract X and y from the data frame\n",
        "X = data_frame['Message'].tolist()\n",
        "y = data_frame['Category'].tolist()\n",
        "\n",
        "\n",
        "# Initialize label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Print the first 5 elements of X and y\n",
        "print(f'X[:5]: \\n{X[:5]}\\n')\n",
        "print(f'y[:5]: {y[:5]}\\n')\n",
        "print(f\"Label Mapping : {label_encoder.inverse_transform(y[:5])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us2Wdf5Xgt07"
      },
      "source": [
        "Great! We have completed the first step of loading the data. However, the data is currently in a raw format which needs to be preprocessed in order to make it compatible with the model.\n",
        "\n",
        "---\n",
        "\n",
        "There are **multiple ways** to create a **label mapping dictionary**, one of which is creating it **manually**. This process can be **time-consuming**, but it can provide **more control and flexibility** in terms of **label mapping**. However, there's also an **easier way** to do it using **label encoder**.\n",
        "\n",
        "In this approach, the **label encoder** assigns a **unique numerical label to each class**, starting from **zero**. For example, in our case, the **label encoder encoded** the class **\"ham\" as 0** and **\"spam\" as 1**. This way, we can **quickly map each class** to its **corresponding numerical label** without the need for **manual dictionary creation**.\n",
        "\n",
        "In this case, there are just **two classes**, so **manual dictionary will be equally effective**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3pdOYJ-gt08"
      },
      "source": [
        "# **Text Vectorization**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS9zvgIegt08"
      },
      "source": [
        "One way to handle **class imbalances** to use **SMOTE algorithm**. When applying **SMOTE** to **text data**, the **input features** are usually represented as **vectors of numerical values** using **techniques such as bag-of-words, TF-IDF, or word embeddings**. These **numerical vectors** can then be used as input to the **SMOTE algorithm** to **generate synthetic data points**.\n",
        "\n",
        "However, it is **important** to **note** that **SMOTE may not always be the best technique** for **addressing class imbalance** in **text data**. **Text data** is often **high-dimensional and sparse**, which can make it **challenging to generate meaningful synthetic data points**. In some cases, **alternative techniques** such as **data augmentation** or **cost-sensitive learning** may be **more effective** for **improving the performance** of **machine learning models** trained on **imbalanced text data**.\n",
        "\n",
        "In summary, **SMOTE** can work with text data, but its **effectiveness** will depend on the **specific characteristics** of the **data** and the project's needs and constraints.\n",
        "\n",
        "\n",
        "Here we will use **Cost-Sensitive Learning**.\n",
        "* **Cost-sensitive learning**: Modifying the **machine learning algorithm** to give **higher weights** to the **minority class**. This approach works by **penalizing** the **model more for misclassifying the minority class**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OapJ7mkfgt08",
        "outputId": "1caa1057-79a6-4a8b-a935-845b3ee16644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Associated class weights: {0: 0.5774093264248704, 1: 3.7295850066934406}\n"
          ]
        }
      ],
      "source": [
        "# Compute class weights\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=data_frame.Category.unique(), y=label_encoder.inverse_transform(y))\n",
        "class_weights = {number: weight for number, weight in enumerate(class_weights)}\n",
        "# Show\n",
        "print(f\"Associated class weights: {class_weights}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgDISby5gt08"
      },
      "source": [
        "Based on the **computed class weights**, we can observe that the **second class (i.e., \"spam\")** has a **higher weight** of **3.72958501**, while the **first class (i.e., \"ham\")** has a **lower weight** of **0.57740933**. This indicates that the **second class** is **more important** for the **classification task** and the model will be trained to **give more weight** to this **class during training.** On the other hand, the **first class** is **relatively less important** and will be given **less weight during training**.\n",
        "\n",
        "Therefore, we can say that the **class weights** are **aligned with our expectations**, where we **wanted to prioritize** the **spam class** as it is the **target class** we want to **detect accurately**.\n",
        "\n",
        "---\n",
        "We just dealed with **class Imbalance**. It's time to move ahead to **natural language processing.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BEYRnuegt08"
      },
      "outputs": [],
      "source": [
        "# Define a function to preprocess the text\n",
        "def preprocess_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Preprocesses the text by removing punctuation, lowercasing, and stripping whitespace.\n",
        "    \"\"\"\n",
        "    # Replace punctuation with spaces\n",
        "    text = tf.strings.regex_replace(text, f\"[{string.punctuation}]\", \" \")\n",
        "\n",
        "    # Lowercase the text\n",
        "    text = tf.strings.lower(text)\n",
        "\n",
        "    # Strip leading/trailing whitespace\n",
        "    text = tf.strings.strip(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# Create a TextVectorization layer\n",
        "text_vectorizer = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,                       # Maximum vocabulary size\n",
        "    output_sequence_length=max_seq_len,          # Maximum sequence length\n",
        "    standardize=preprocess_text,                 # Custom text preprocessing function\n",
        "    pad_to_max_tokens=True,                      # Pad sequences to maximum length\n",
        "    output_mode='int'                            # Output integer-encoded sequences\n",
        ")\n",
        "\n",
        "# Adapt the TextVectorization layer to the data\n",
        "text_vectorizer.adapt(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YEYciV8gt08"
      },
      "source": [
        "Let's see the Text Vectorization working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1L0u4T3gt08",
        "outputId": "7b24cefa-0a4b-4824-bd85-6e347546fcfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text: Ard 4 lor...\n",
            "Vectorized Text: [569  44  86   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0]\n",
            "\n",
            "Original Text: Nowadays people are notixiquating the laxinorficated opportunity for bambling of entropication.... Have you ever oblisingately opted ur books for the masteriastering amplikater of fidalfication? It is very champlaxigating, i think it is atrocious.. Wotz Ur Opinion???? Junna\n",
            "Vectorized Text: [3435  271   24 6074    6 6479 1767   14 8098   16 7302   19    4  372\n",
            " 6045 5987   35 2822   14    6 6314 8267   16 7193   13   10  176 7823\n",
            "    2  112   13   10 8162 4482   35 1233 6582    0    0    0]\n",
            "\n",
            "Original Text: Que pases un buen tiempo or something like that\n",
            "Vectorized Text: [5637 5901  831 7911 4868   31  200   59   18    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "\n",
            "Original Text: Moby Pub Quiz.Win a 100 High Street prize if u know who the new Duchess of Cornwall will be? Txt her first name to 82277.unsub STOP 1.50 008704050406 SP\n",
            "Vectorized Text: [2063  657  753  183    5  512 1412 1022  158   38    7   58  119    6\n",
            "  106 3871   16 2762   37   39   77  110  211  272    3 1465 1318   90\n",
            "  324  242 4374 1206    0    0    0    0    0    0    0    0]\n",
            "\n",
            "Original Text: I accidentally brought em home in the box\n",
            "Vectorized Text: [   2 2249 2204 1071   83    9    6  349    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _ in range(5):\n",
        "    # Send a text to randomly.\n",
        "    text_temp = X[np.random.randint(N_SAMPLES)]\n",
        "\n",
        "    # Apply text to vectorization.\n",
        "    text_vec_temp = text_vectorizer(text_temp)\n",
        "\n",
        "    # Show the results\n",
        "    print(f\"Original Text: {text_temp}\")\n",
        "    print(f\"Vectorized Text: {text_vec_temp}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbqGqJFqgt09",
        "outputId": "2f3267ac-7a81-4bae-e532-8aba832dba6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 8841\n",
            "Vocabulary: ['number', 'message', 'e', 've', 'tomorrow', 'say', 'won', 'right', 'prize', 'already', 'after', 'said', 'ask', 'doing', 'cash', 'amp', '3', 'yeah', 'really', 'im', 'why', 'b', 'life', 'them', 'meet', 'find', 'very', 'miss', 'morning', 'let', 'babe', 'last', 'would', 'win', 'thanks', 'cos', 'anything', 'uk', 'lol', 'also', 'care', 'every', 'sure', 'pick', 'com', '150p', 'sent', 'nokia', 'keep', 'urgent']\n"
          ]
        }
      ],
      "source": [
        "# Get the vocabulary\n",
        "VOCAB = text_vectorizer.get_vocabulary()\n",
        "\n",
        "# Let's have a look at the tokens present in the vocabulary\n",
        "print(f\"Vocabulary size: {len(VOCAB)}\")\n",
        "print(f\"Vocabulary: {VOCAB[150:200]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aLmr0xjgt09"
      },
      "source": [
        "The **vocabulary size** indicates the **total number of unique words** in the **corpus**, which in this case is **8841**. The **list of words** in the **vocabulary** seems to be **sorted in descending order** of **frequency**, with the **most frequent words** appearing at the **top**. The **words in the vocabulary** seem to be **mostly related** to **text messaging**, such as **\"message,\" \"tomorrow,\" \"said,\" \"win,\" and \"urgent,\"** among others. The **vocabulary** also **contains some commonly used words** and **abbreviations**, such as **\"ve,\" \"amp,\" \"lol,\" and \"cos.\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPHvhaMNgt09"
      },
      "source": [
        "## **Data Splitting**\n",
        "---\n",
        "\n",
        "As we have our processing functions ready, let's split the data into **training and testing**, and also apply the **Text Vectorization**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adRZvyLcgt09"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42, shuffle=True)\n",
        "\n",
        "# Apply the Text Vectorization\n",
        "X_train = text_vectorizer(X_train)\n",
        "X_test = text_vectorizer(X_test)\n",
        "\n",
        "# One Hot Vectors\n",
        "Xoh_train = tf.one_hot(X_train, depth=10000)\n",
        "Xoh_test  = tf.one_hot(X_test, depth=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbdxfT1igt09"
      },
      "source": [
        "# **Transformer Network**\n",
        "---\n",
        "\n",
        "![image.png](attachment:9d28e3f3-e714-4e43-8778-e1e31d0035f1.png)\n",
        "\n",
        "The **Transformer network** is a **deep neural network architecture** that is **widely** used for **natural language processing tasks**, including **text classification**. The **network comprises** a **stack of Transformer blocks**, each containing **two sub-layers**:\n",
        "* The *self-attention layer(more spedifically MHA)*\n",
        "* The *feedforward layer*.\n",
        "\n",
        "The **self-attention layer** is the **key component** of the **Transformer network** that enables it to capture the dependencies **between different words** in a sentence. It works by computing a **weighted sum** of the **embeddings** of **all the words** in the **sentence**, where the **weights** are determined by the **attention scores** between **pairs of words**. These **attention scores** are calculated by taking the **dot product of the embeddings** of the **words** and applying a **softmax function** to the **result**, resulting in a **weight distribution** that reflects the **relevance of each word to every other word in the sentence**.\n",
        "\n",
        "The **feedforward layer** is a **simple two-layer neural network** that processes the output of the **self-attention layer** and applies a **non-linear transformation** to it.\n",
        "\n",
        "The **multi-head attention mechanism** is a **variation** of the **self-attention layer** in which the **attention scores** are **calculated multiple times** with **different linear projections** of the **input embeddings**. This **enables the network** to attend to **different aspects** of the **input embeddings in parallel**, which can lead to **better performance on certain tasks**.\n",
        "\n",
        "For **text classification**, the **Transformer network** takes the **input text** as a **sequence of word embeddings** and passes it through **multiple Transformer blocks**. The **final output** of the **network** is a **vector representation** of the **input text** that can be used for **classification** using a **softmax layer**. By using the **self-attention mechanism** and the **multi-head attention mechanism**, the network can capture the **semantic relationships** between **different words** in the text and **produce highly accurate predictions.**\n",
        "\n",
        "Before creating the **transformer layer**, let's first create the **Word and Positional embedding layer**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLrEQON3gt09"
      },
      "outputs": [],
      "source": [
        "class TokenAndPositionalEmbedding(layers.Layer):\n",
        "\n",
        "    def __init__(self, embedding_dims, vocab_size, seq_len, **kwargs):\n",
        "        super(TokenAndPositionalEmbedding, self).__init__(**kwargs)\n",
        "\n",
        "        # Initialize parameters\n",
        "        self.seq_len = seq_len\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dims = embedding_dims\n",
        "        self.embed_scale = tf.math.sqrt(tf.cast(embedding_dims, tf.float32))\n",
        "\n",
        "        # Define layers\n",
        "        self.token_embedding = layers.Embedding(\n",
        "            input_dim=vocab_size,\n",
        "            output_dim=embedding_dims,\n",
        "            name=\"token_embedding\"\n",
        "        )\n",
        "\n",
        "        self.positional_embedding = layers.Embedding(\n",
        "            input_dim=seq_len,\n",
        "            output_dim=embedding_dims,\n",
        "            name=\"positional_embedding\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        seq_len = tf.shape(inputs)[1]\n",
        "\n",
        "        # Token Embedding\n",
        "        token_embedding = self.token_embedding(inputs)\n",
        "        token_embedding *= self.embed_scale\n",
        "\n",
        "        # Positional Embedding\n",
        "        positions = tf.range(start=0, limit=seq_len, delta=1)\n",
        "        positional_embedding = self.positional_embedding(positions)\n",
        "\n",
        "        # Add Token and Positional Embedding\n",
        "        embeddings = token_embedding + positional_embedding\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(TokenAndPositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            'embedding_dims': self.embedding_dims,\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'seq_len': self.seq_len,\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8FNvK7kgt09"
      },
      "outputs": [],
      "source": [
        "# Let's look what the layer do.\n",
        "temp_embeds = TokenAndPositionalEmbedding(embed_dim, vocab_size, max_seq_len)(X_train[:1])\n",
        "temp_embeds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsW1ICNDgt09"
      },
      "source": [
        "The **Embedding layer** in a **neural network** is a **crucial component** that **plays a key role** in **converting text data** into **meaningful numerical representations**. Essentially, the **Embedding layer** creates a **word embedding**(also known as the **token embedding**), which **projects** the **input indexes**, (i.e., the tokens), into a **feature space**(or vector space), that **contains unique and informative representations for each token**(or word).\n",
        "\n",
        "Additionally, it computes the **positional embeddings,** which represent the **positions** of the **tokens** in the **input sequence**. While traditionally, this was achieved using **sine and cosine waves**, here we have **leveraged the power of the Embedding layer** to handle this task in a **more efficient and effective manner**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfmhnA5jgt0-"
      },
      "source": [
        "## **Transformer Layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVgWmyixgt0-"
      },
      "outputs": [],
      "source": [
        "class TransformerLayer(layers.Layer):\n",
        "\n",
        "    def __init__(self, num_heads: int, dropout_rate: float, embedding_dims: int, ff_dim: int, **kwargs):\n",
        "        super(TransformerLayer, self).__init__(**kwargs)\n",
        "\n",
        "        # Initialize Parameters\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.embedding_dims = embedding_dims\n",
        "        self.ff_dim = ff_dim\n",
        "\n",
        "        # Initialize Layers\n",
        "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dims, dropout=dropout_rate)\n",
        "        self.ln1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.ffn = keras.Sequential([\n",
        "            layers.Dense(ff_dim, activation='relu', kernel_initializer='he_normal'),\n",
        "            layers.Dense(embedding_dims)\n",
        "        ])\n",
        "        self.ln2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Forward pass of the Transformer Layer.\n",
        "\n",
        "        Args:\n",
        "            inputs: Tensor with shape `(batch_size, seq_len, embedding_dims)` representing the input sequence.\n",
        "\n",
        "        Returns:\n",
        "            Tensor with shape `(batch_size, seq_len, embedding_dims)` representing the output sequence after applying the Transformer Layer.\n",
        "        \"\"\"\n",
        "\n",
        "        # Multi-Head Attention\n",
        "        attention = self.mha(inputs, inputs, inputs)\n",
        "\n",
        "        # Layer Normalization and Residual Connection\n",
        "        normalized1 = self.ln1(attention + inputs)\n",
        "\n",
        "        # Feedforward Network\n",
        "        ffn_out = self.ffn(normalized1)\n",
        "\n",
        "        # Layer Normalization and Residual Connection\n",
        "        normalized2 = self.ln2(ffn_out + normalized1)\n",
        "\n",
        "        return normalized2\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"Get the configuration of the Transformer Layer.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with the configuration of the layer.\n",
        "        \"\"\"\n",
        "        config = super(TransformerLayer, self).get_config()\n",
        "        config.update({\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "            \"embedding_dims\": self.embedding_dims,\n",
        "            \"ff_dim\": self.ff_dim\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5GVSojegt0-"
      },
      "outputs": [],
      "source": [
        "# Transformer layers execution\n",
        "TransformerLayer(num_heads=num_heads, embedding_dims=embed_dim, ff_dim=ff_dim, dropout_rate=0.1)(temp_embeds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzmmH7Pkgt0-"
      },
      "source": [
        "# **Transformer Text Classification Model**\n",
        "---\n",
        "\n",
        "It's time to combine the **Token and Positional Embedding** layer and the **Transformer layer** to make a **Transformer Network architecture** for **text classification**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlJYUDH7gt0-"
      },
      "outputs": [],
      "source": [
        "# Input layer\n",
        "InputLayer = layers.Input(shape=(max_seq_len,), name=\"InputLayer\")\n",
        "\n",
        "# Embedding Layer\n",
        "embeddings = TokenAndPositionalEmbedding(embed_dim, vocab_size, max_seq_len, name=\"EmbeddingLayer\")(InputLayer)\n",
        "\n",
        "# Transformer Layer\n",
        "encodings = TransformerLayer(num_heads=num_heads, embedding_dims=embed_dim, ff_dim=ff_dim, dropout_rate=0.1, name=\"TransformerLayer\")(embeddings)\n",
        "\n",
        "# Classifier\n",
        "gap = layers.GlobalAveragePooling1D(name=\"GlobalAveragePooling\")(encodings)\n",
        "drop = layers.Dropout(0.5, name=\"Dropout\")(gap)\n",
        "OutputLayer = layers.Dense(1, activation='sigmoid', name=\"OutputLayer\")(drop)\n",
        "\n",
        "# Model\n",
        "model = keras.Model(InputLayer, OutputLayer, name=\"TransformerNet\")\n",
        "\n",
        "# Model Architecture Summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWhmqj-Mgt0-"
      },
      "source": [
        "# **Transformer Training**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sWKglC1gt0_"
      },
      "outputs": [],
      "source": [
        "# Compile the Model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=[\n",
        "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "        keras.metrics.Precision(name='precision'),\n",
        "        keras.metrics.Recall(name='recall'),\n",
        "        keras.metrics.AUC(name='auc'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train Model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs8NJ9zGgt0_"
      },
      "outputs": [],
      "source": [
        "# Plot metrics\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 8))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "axes[0, 0].plot(history.history['loss'], label='Training Loss')\n",
        "axes[0, 0].plot(history.history['val_loss'], label='Validation Loss')\n",
        "axes[0, 0].set_title('Loss', fontsize=14)\n",
        "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
        "axes[0, 0].grid(True)\n",
        "axes[0, 0].legend(fontsize=10)\n",
        "\n",
        "axes[0, 1].plot(history.history['accuracy'], label='Training Accuracy')\n",
        "axes[0, 1].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "axes[0, 1].set_title('Accuracy', fontsize=14)\n",
        "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0, 1].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[0, 1].grid(True)\n",
        "axes[0, 1].legend(fontsize=10)\n",
        "\n",
        "axes[1, 0].plot(history.history['precision'], label='Training Precision')\n",
        "axes[1, 0].plot(history.history['val_precision'], label='Validation Precision')\n",
        "axes[1, 0].set_title('Precision', fontsize=14)\n",
        "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1, 0].set_ylabel('Precision', fontsize=12)\n",
        "axes[1, 0].grid(True)\n",
        "axes[1, 0].legend(fontsize=10)\n",
        "\n",
        "axes[1, 1].plot(history.history['recall'], label='Training Recall')\n",
        "axes[1, 1].plot(history.history['val_recall'], label='Validation Recall')\n",
        "axes[1, 1].set_title('Recall', fontsize=14)\n",
        "axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1, 1].set_ylabel('Recall', fontsize=12)\n",
        "axes[1, 1].grid(True)\n",
        "axes[1, 1].legend(fontsize=10)\n",
        "\n",
        "fig.suptitle('Model Performance Metrics', fontsize=16, y=1.05)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsctvWg7gt1A"
      },
      "outputs": [],
      "source": [
        "# Evaluate model performance on test data\n",
        "loss, acc, precision, recall, auc = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Show the model performance\n",
        "print('Test loss      :', loss)\n",
        "print('Test accuracy  :', acc*100)\n",
        "print('Test precision :', precision*100)\n",
        "print('Test recall    :', recall*100)\n",
        "print('Test AUC       :', auc*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5t4qrYrgt1A"
      },
      "source": [
        "Looking at the **training curve**, **one might think** that the **model is diverging** and the **performance is deteriorating.** However, upon **evaluating** the **model's performance** on the **testing data**, we see that the **model is actually performing great** and is able to **generalize on new samples**. This shows that the **model weights** are **robust** and **capable of working** on **new samples**.\n",
        "\n",
        "Now, you might be wondering that this is an **extremely simple architecture**. Although the **architecture is simple**, we are **still getting awesome performance**. That's why **I'm not focusing** on **improving the model architecture** at this point. It's always a **good idea** to **start with a simple model** and then **gradually increase the complexity as required**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MDE6_oPgt1A"
      },
      "source": [
        "# **Transformer Predictions**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqM_1jy6gt1A"
      },
      "outputs": [],
      "source": [
        "def decode_tokens(tokens):\n",
        "    \"\"\"\n",
        "    This function takes in a list of tokenized integers and returns the corresponding text based on the provided vocabulary.\n",
        "\n",
        "    Args:\n",
        "    - tokens: A list of integers representing tokenized text.\n",
        "    - vocab: A list of words in the vocabulary corresponding to each integer index.\n",
        "\n",
        "    Returns:\n",
        "    - text: A string of decoded text.\n",
        "    \"\"\"\n",
        "    text = \" \".join(VOCAB[int(token)] for token in tokens).strip()\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfL1Rs7lgt1A"
      },
      "outputs": [],
      "source": [
        "for _ in range(10):\n",
        "    # Randomly select a text from the testing data.\n",
        "    index = np.random.randint(1,len(X_test))\n",
        "    tokens = X_test[index-1:index]\n",
        "    label = y_test[index]\n",
        "\n",
        "    # Feed the tokens to the model\n",
        "    print(f\"\\nModel Prediction\\n{'-'*100}\")\n",
        "    proba = 1 if model.predict(tokens, verbose=0)[0][0]>0.5 else 0\n",
        "    pred = label_encoder.inverse_transform([proba])\n",
        "    print(f\"Message: '{decode_tokens(tokens[0])}' | Prediction: {pred[0].title()} | True : {label_encoder.inverse_transform([label])[0].title()}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ68t6HVgt1A"
      },
      "source": [
        "Note: You might get all the predictions to be predicted as \"ham\" initially. But, this does not mean the model only predicts one class. It is possible that the first few inputs you tried were actually \"ham\" messages. You can try running the cell multiple times with different inputs, and you will find that the model will predict \"spam\" as well. This variability in predictions is expected, and it's a good sign that the model is generalizing to new samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZAeBKyjgt1A"
      },
      "outputs": [],
      "source": [
        "# Custom Input\n",
        "text = input(\"Enter your Msg: \")\n",
        "\n",
        "# Convert into tokens\n",
        "tokens = text_vectorizer([text])\n",
        "\n",
        "# Feed the tokens to the model\n",
        "print(f\"\\nModel Predictions\\n{'-'*100}\")\n",
        "proba = 1 if model.predict(tokens, verbose=0)[0][0]>0.5 else 0\n",
        "pred = label_encoder.inverse_transform([proba])\n",
        "print(f\"Message: '{text}' | Prediction: {pred[0].title()}\")\n",
        "\n",
        "# This is not supported."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHYCblyegt1A"
      },
      "source": [
        "After completing the Transformer Predictions section, we have a fully functional model that can take input from users and classify them as spam or ham. Feel free to try out the model yourself by providing some sample texts and see how the model responds.\n",
        "\n",
        "---\n",
        "## **Summary**\n",
        "\n",
        "Sure, here's a summary of the code and its steps:\n",
        "\n",
        "* **SetUp:** Importing necessary libraries and defining constants and hyperparameters.\n",
        "\n",
        "* **Data Loading:** Loading the SMS spam/ham dataset.\n",
        "\n",
        "* **Text Vectorization:** Preprocessing the text data using the TextVectorization layer from TensorFlow, which tokenizes the text and converts them to numerical values.\n",
        "\n",
        "* **Transformer Network:** Creating the transformer network architecture using the Keras functional API. This includes creating token and word embeddings, positional embeddings, and a multi-head self-attention layer.\n",
        "\n",
        "* **Transformer Training:** Compiling and training the transformer network on the preprocessed SMS data. The training is performed on the training set and validated on the validation set.\n",
        "\n",
        "* **Evaluation:** Evaluating the model on the test set to check its generalization capability and plot different metrics.\n",
        "\n",
        "* **Custom Input:** Taking input from the user and using the trained model to classify the input text as spam or ham.\n",
        "\n",
        "---\n",
        "**DeepNets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoIO61iXxm10"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
